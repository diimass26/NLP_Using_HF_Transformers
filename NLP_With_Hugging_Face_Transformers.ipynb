{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CztodpmQM11q"
      },
      "source": [
        "# Let's try HuggingFace Transformers NLP Pipelines!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing transformers"
      ],
      "metadata": {
        "id": "jjacY6rUpcDg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dtAhiTAMmYN",
        "outputId": "6e5bea2c-63e6-46e8-e5de-9d9b3d31844d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Zero Shot Classification Pipeline"
      ],
      "metadata": {
        "id": "MbrtLvD3phMv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3g0V_WTMpwB",
        "outputId": "5066b8ea-458e-41b7-e99f-33fcfe5e1fb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'I love hanging out in cafes, enjoying a cup of coffee in my free time.',\n",
              " 'labels': ['hobby', 'entertainment', 'personality'],\n",
              " 'scores': [0.7580190300941467, 0.1480296403169632, 0.09395135939121246]}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "\n",
        "text = \"I love hanging out in cafes, enjoying a cup of coffee in my free time.\"\n",
        "candidate_labels = [\"hobby\", \"personality\", \"entertainment\"]\n",
        "classifier(text, candidate_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Text Generation Pipeline"
      ],
      "metadata": {
        "id": "HD9IapW9pov5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qwkn1wZaNCxn",
        "outputId": "8361b65d-5983-4c7c-a076-190d58f7c1cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"Once upon a time in a distant land, we heard of the old boy, now young, who was a good horse who'd rode all the way from Cape Breton to St. John's. He kept his hands out of the hands of the\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"Once upon a time in a distant land,\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drVV_RinNMws",
        "outputId": "f0b7cc03-be27-4aa1-e4df-0dcd5111a685"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"Once upon a time in a distant land, they were not so sure what would come. They didn't know what could happen in the future and would be waiting to see them.\\nBut they hadn't heard anything before. The only thing they had\"},\n",
              " {'generated_text': 'Once upon a time in a distant land, one man will have to go to sleep and find something to find. This will happen only with the help of a friend. Once you have decided all steps of the man, you will have to start doing'},\n",
              " {'generated_text': 'Once upon a time in a distant land, the first one of two ships to go along with Ipthac (another ship to go along with the other, to the sea where Ipthac is being piloted by a crew of a'}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\n",
        "    \"Once upon a time in a distant land,\",\n",
        "    max_length=50,\n",
        "    num_return_sequences=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Fill Mask Pipeline"
      ],
      "metadata": {
        "id": "KZE4WkhBpyd1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ab97He7Dd0k",
        "outputId": "d3eccc9f-6228-4238-c2b4-8e9a765ef3bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.1335359811782837,\n",
              "  'token': 3581,\n",
              "  'token_str': ' sleep',\n",
              "  'sequence': \"I'll get some sleep because im so stressing right now.\"},\n",
              " {'score': 0.06626366078853607,\n",
              "  'token': 18803,\n",
              "  'token_str': ' pics',\n",
              "  'sequence': \"I'll get some pics because im so stressing right now.\"},\n",
              " {'score': 0.02399718388915062,\n",
              "  'token': 1079,\n",
              "  'token_str': ' rest',\n",
              "  'sequence': \"I'll get some rest because im so stressing right now.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "unmasker = pipeline(\"fill-mask\")\n",
        "unmasker(\"I'll get some <mask> because im so stressing right now.\", top_k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Using Named Entity Recognition (NER) Pipeline"
      ],
      "metadata": {
        "id": "XzTQVjiLqhCB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-uxwPRKDhpB",
        "outputId": "918e6649-846d-40ea-e07f-de52bfd1e772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.9986572,\n",
              "  'word': 'Dimas',\n",
              "  'start': 11,\n",
              "  'end': 16},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.98387563,\n",
              "  'word': 'Raja Ali Haji University',\n",
              "  'start': 34,\n",
              "  'end': 58},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.9987993,\n",
              "  'word': 'Indonesia',\n",
              "  'start': 62,\n",
              "  'end': 71}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "ner(\"My name is Dimas and I student at Raja Ali Haji University in Indonesia.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Question Answering Pipeline"
      ],
      "metadata": {
        "id": "1lYWJgpxrMDX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SbkDlwfDlF5",
        "outputId": "2745fbf5-8f13-4355-b7d8-bbc33e439d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jawaban: IKN\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "context = \"Indonesia is the country in Southeast Asia, IKN is its capital city and its a new capital city of Indonesia\"\n",
        "question = \"What is Indonesia capital city?\"\n",
        "\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "print(f\"Jawaban: {result['answer']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Sentiment Analysis Pipeline"
      ],
      "metadata": {
        "id": "1UWVmCa-sdtP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3IZcIeAE41r",
        "outputId": "2000b2c9-37db-4f89-97ba-fc7502f122da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9974888563156128}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"I love using Hugging Face Transformers! It's so easy to use.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Summarization Pipeline"
      ],
      "metadata": {
        "id": "ZO-j_0Fds5i2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXSjHIImDptH",
        "outputId": "00f6e01b-6bd9-4810-a220-c6159724ff3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn like humans . AI can be classified into two main categories: narrow AI and general AI . Narrow AI is designed and trained for specific tasks, such as facial recognition or internet searches . Strong AI aims to perform any intellectual task a human can do that a human being can do .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    Artificial Intelligence (AI) refers to the simulation of human intelligence\n",
        "    in machines programmed to think and learn like humans. The term is often used\n",
        "    to describe machines or computers that can perform tasks typically requiring human\n",
        "    intelligence, such as visual perception, speech recognition, decision-making, and language translation.\n",
        "    AI can be classified into two main categories: narrow AI and general AI.\n",
        "    Narrow AI, also known as weak AI, is designed and trained for specific tasks,\n",
        "    such as facial recognition or internet searches. Examples include voice assistants\n",
        "    like Siri and Alexa, as well as recommendation systems used by platforms like Netflix and Amazon.\n",
        "    On the other hand, general AI, or strong AI, aims to perform any intellectual task\n",
        "    that a human being can do. While this type of AI remains theoretical at this point,\n",
        "    advancements in machine learning and deep learning are paving the way for developments\n",
        "    that could eventually lead to general AI.\n",
        "    The applications of AI are vast and include industries such as healthcare, finance,\n",
        "    education, and transportation. For instance, in healthcare, AI systems can analyze\n",
        "    medical data to assist in diagnosing diseases and predicting patient outcomes.\n",
        "    In finance, AI algorithms are used for fraud detection and automated trading.\n",
        "    As AI technology continues to evolve, ethical considerations regarding its impact\n",
        "    on society and the workforce become increasingly important. Issues such as privacy,\n",
        "    bias in AI algorithms, and the potential for job displacement are critical topics of\n",
        "    discussion among policymakers, researchers, and industry leaders.\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Translation Pipeline"
      ],
      "metadata": {
        "id": "6EOcEye0uNam"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxr6a3YYDtmL",
        "outputId": "82a97888-9a2b-428e-eb0c-879c58d96932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love coffee so much, I drink coffee every day\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation_id_to_en\", model=\"Helsinki-NLP/opus-mt-id-en\")\n",
        "\n",
        "text_to_translate = \"Saya sangat suka kopi, saya minum kopi setiap hari\"\n",
        "result = translator(text_to_translate)\n",
        "\n",
        "print(result[0]['translation_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vbYVRh2bn4y"
      },
      "source": [
        "## Analysis\n",
        "- Zero-Shot Classification, memungkinkan model untuk mengklasifikasikan teks ke dalam kategori yang tidak pernah dilatih sebelumnya. Hasil klasifikasi mencerminkan relevansi teks dengan label yang diberikan.\n",
        "- Text Generation, menggunakan model untuk melanjutkan teks atau menghasilkan konten baru berdasarkan prompt yang diberikan.\n",
        "- Fill Mask, digunakan untuk mengisi kata yang hilang dalam kalimat. Ini sangat berguna untuk memperbaiki kalimat.\n",
        "- Named Entity Recognition (NER), berfungsi untuk mengidentifikasi dan mengklasifikasikan entitas dalam teks, seperti nama orang, lokasi, dan organisasi.\n",
        "- Question Answering, memungkinkan pengguna untuk mendapatkan jawaban langsung berdasarkan konteks yang diberikan.\n",
        "- Sentiment Analysis, digunakan untuk menentukan perasaan atau opini yang terkandung dalam teks.\n",
        "- Summarization, bertujuan untuk merangkum teks panjang menjadi versi yang lebih ringkas dan mudah dicerna.\n",
        "- Translation, memungkinkan konversi teks dari satu bahasa ke bahasa lain.\n",
        "\n",
        "Hugging Face Transformers menyediakan beragam pipeline yang memungkinkan pengguna untuk melakukan berbagai tugas pemrosesan bahasa alami (NLP) dengan mudah dan efektif. Setiap pipeline memiliki kekuatan dan aplikasi khusus, yang dapat dimanfaatkan untuk meningkatkan efisiensi dan akurasi dalam berbagai kasus.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}